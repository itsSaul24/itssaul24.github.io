---
layout: post
title: March Madness Prediction
published: true
order: 1
description: >
  A dataâ€‘science capstone from my final semester at Purdue University.  
  We built several classification models (Logistic Regression, SVM, KNN, Random Forest)
  to predict how many games Purdue would win in the 2024 NCAA Tournament, and evaluated
  them against both business and dataâ€‘science success criteria.
skills:
  - Exploratory Data Analysis
  - Feature Engineering
  - Dimensionality Reduction (PCA)
  - Classification Modeling
  - Model Evaluation & Selection
  - Data Visualization
main-image: /mm_cover.jpg
---

## ğŸ“– Introduction

In this project, we explore historical NCAA data to predict Purdueâ€™s 2024 Tournament performance.  
We walk through data preprocessing, dimensionality reduction, model training, and final probability outputs.

---

## ğŸ“‚ Project Structure

```text
marchmadness-prediction/
â”œâ”€â”€ data/           # CSVs for training, validation, final predictions & raw misc
â”œâ”€â”€ notebooks/      # Jupyter notebooks with analysis & code
â”œâ”€â”€ reports/        # Final PDF reports: evaluation & modeling
â””â”€â”€ slides/         # Presentation decks
``` 

## ğŸ” Data Overview
We split our data into:
- training_data.csv: used to train models
- val_data.csv: validation set for hyperparameter tuning
- final_predictions.csv: hold-out set predictions
- misc_data/: auxiliary datasets used in feature engineering

## ğŸ“Š 2D & 3D PCA Visualizations
Dimensionality reduction helps us inspect variance structure and clustering by team metrics.

2D PCA
{% include image-gallery.html images="mm_2d_pca.png" height="400" %} 
<span style="font-size: 20px">2D PCA of team performance features</span>

3D PCA
{% include image-gallery.html images="mm_3d_pca.png" height="400" %} 
<span style="font-size: 20px">3D PCA of team performance features</span>

## ğŸŒŸ Top 10 Feature Importances (Random Forest)
We trained a Random Forest classifier and extracted the top 10 most influential features.

{% include image-gallery.html images="mm_feature_importance.png" height="400" %} 
<span style="font-size: 20px">Random Forest top 10 feature importances</span>

## ğŸ€ Predicted Win Probabilities
Finally, we generate predicted probabilities for each team in the hold-out tournament bracket.

{% include image-gallery.html images="mm_pred.png" height="800" %} 
<span style="font-size: 20px">Predicted win probability for each team</span>

## ğŸ“ˆ Performance Summary

Across both the initial and fineâ€‘tuned parameter sets, Logistic Regression consistently led in overall classification metrics, while Random Forest was the only model to nail Purdueâ€™s actual tournament outcome exactly.

| Model                   | Initial Accuracy | Tuned Accuracy |
|-------------------------|:----------------:|:--------------:|
| **Logistic Regression** | 0.5641           | 0.6667         |
| SVM                     | 0.4615           | 0.5385         |
| KNN                     | 0.4300           | 0.4839         |
| Random Forest           | 0.4146           | 0.4390         |  

*(Weighted macroâ€‘average across accuracy, precision, recall, F1)* 

---

## âš–ï¸ Predicted vs. Actual Purdue Performance

| Model                   | Predicted Round       | Implied # Wins | Actual Round          | Actual # Wins |
|-------------------------|:---------------------:|:--------------:|:---------------------:|:-------------:|
| Logistic Regression     | FinalÂ Four (Semis)    | 4              | Championship (Final)  | 5             |
| SVM                     | FinalÂ Four (Semis)    | 4              | Championship (Final)  | 5             |
| KNN                     | FinalÂ Four (Semis)    | 4              | Championship (Final)  | 5             |
| **Random Forest**       | Championship Runnerâ€‘up| 5              | Championship (Final)  | 5             |

- Logistic, SVM, and KNN each fell one round short of Purdueâ€™s actual runnerâ€‘up finish (Semis vs. Final) 
- Random Forest uniquely matched the true outcome, correctly predicting Purdueâ€™s path to the championship game

---

## ğŸ¯ Key Takeaways

1. **Business Success:**  
   All models met the â€œwithin 1â€‘round errorâ€ criterion, satisfying our primary objective

2. **Metric Tradeâ€‘Offs:**  
   Despite Random Forestâ€™s perfect bracket prediction for Purdue, its overall accuracy (0.439) lagged behind simpler modelsâ€”underscoring that the highest aggregate score doesnâ€™t always align with specific business goals.  

3. **Feature Insights:**  
   Across models, seed and efficiency differentials (AdjEM, AdjDE) consistently ranked among the top predictors, reaffirming their domain importance.

---

## ğŸ”® Next Steps

- **Ensemble Stacking:** Blend Logistic Regression, SVM, and RF via a metaâ€‘learner to leverage both highâ€‘accuracy and bracketâ€‘precision signals.  
- **Probability Calibration:** Apply Platt scaling or isotonic regression to improve alignment between predicted probabilities and observed frequencies.  
- **Gameâ€‘byâ€‘Game Modeling:** Explore a sequential model that predicts each matchup individuallyâ€”potentially boosting overall tournamentâ€‘level accuracy.  
- **Live Updating:** Integrate inâ€‘season and inâ€‘tournament feeds (injuries, momentum metrics) to dynamically adjust win probabilities roundâ€‘byâ€‘round.

## ğŸ”— GitHub

You can explore the source code here:  
ğŸ‘‰ [View on GitHub](https://github.com/itsSaul24/marchmadness-prediction)

---